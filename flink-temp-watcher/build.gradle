plugins {
    // https://docs.gradle.org/current/userguide/idea_plugin.html
    id 'idea'

    // https://docs.gradle.org/current/userguide/application_plugin.html
    id 'application'

    // https://plugins.gradle.org/plugin/com.adarshr.test-logger
    id 'com.adarshr.test-logger' version '3.0.0'

    // https://imperceptiblethoughts.com/shadow/introduction/
    id 'com.github.johnrengelman.shadow' version '7.1.2'

    id "com.diffplug.spotless"

}

java {
    toolchain {
        languageVersion = JavaLanguageVersion.of(11)
    }
}

// artifact properties
group = 'org.myorg.quickstart'
version = '0.1'
mainClassName = 'app.tempwatcher.StreamingJob'
description = """Flink Temp Watcher Job"""

application {
  applicationDefaultJvmArgs = ["-Dlog4j.configurationFile=conf/flink/log4j-local.properties"]
}

run {
    environment "FLINK_ENV", "local"
}

task generateAvroJava(type: Exec) {
    commandLine "java", "-jar", "scripts/avro-tools-1.11.1.jar", "compile", "schema", "scripts/sensor_reading.avsc", "src/main/java/"
    commandLine "java", "-jar", "scripts/avro-tools-1.11.1.jar", "compile", "schema", "scripts/sensor_reading_avg.avsc", "src/main/java/"
}

task kafkaUp(type: Exec) {
    commandLine "docker-compose", "-p", "kafka", "-f", "docker/kafka-cluster.yml", "up"
}

task kafkaDown(type: Exec) {
    commandLine "docker-compose", "-p", "kafka", "-f", "docker/kafka-cluster.yml", "down"
}

task stopJob(type: Exec) {
    commandLine "docker-compose", "-p", "flink", "-f", "docker/flink-job-cluster.yml", "down"
}

task registerSchemas(type: Exec) {
    commandLine "/bin/bash", "scripts/register-schema.sh", "scripts/sensor_reading.avsc", "sensor-reading-value"
    commandLine "/bin/bash", "scripts/register-schema.sh", "scripts/sensor_reading_avg.avsc", "sensor-reading-avg-value"

}

task startJob(type: Exec, dependsOn: 'stopJob') {
    commandLine "docker-compose", "-p", "flink", "-f", "docker/flink-job-cluster.yml", "up", "-d"
}

task createTopics(type: Exec) {
    dependsOn registerSchemas
    commandLine "./scripts/create-topics.sh", "sensor-reading", "sensor-reading-avg"
}

task grafanaDown(type: Exec) {
    commandLine "docker-compose", "-p", "grafana", "-f", "docker/grafana-elastic-logstash.yml", "down"
}

task grafanaUp(type: Exec) {
  commandLine "docker-compose", "-p", "grafana", "-f", "docker/grafana-elastic-logstash.yml", "up"
}

tasks.withType(JavaCompile) {
    options.encoding = 'UTF-8'
}


wrapper {
    gradleVersion = '7.4'
}

// declare where to find the dependencies of your project
repositories {
    mavenCentral()
    maven { url "https://packages.confluent.io/maven/" }
}

ext {
    avroVersion = '1.11.1'
    junitVersion = '5.8.2'
    assertjVersion = '3.20.2'
    flinkVersion = '1.16.0'
    slf4jVersion = '1.7.32'
    log4jVersion = '2.17.0'
    kafkaSchemaRegistryVersion = '7.3.1'
    typesafeVersion = '1.4.0'
}

// NOTE: We cannot use "compileOnly" or "shadow" configurations since then we could not run code
// in the IDE or with "gradle run". We also cannot exclude transitive dependencies from the
// shadowJar yet (see https://github.com/johnrengelman/shadow/issues/159).
// -> Explicitly define the // libraries we want to be included in the "flinkShadowJar" configuration!
configurations {
    flinkShadowJar // dependencies which go into the shadowJar

    // always exclude these (also from transitive dependencies) since they are provided by Flink
    flinkShadowJar.exclude group: 'org.apache.flink', module: 'force-shading'
    flinkShadowJar.exclude group: 'com.google.code.findbugs', module: 'jsr305'
    flinkShadowJar.exclude group: 'org.slf4j'
    flinkShadowJar.exclude group: 'org.apache.logging.log4j'

    // https://logging.apache.org/log4j/2.x/faq.html#exclusions
    // Good Explanation: https://stackoverflow.com/questions/42348755/class-path-contains-multiple-slf4j-bindings-error
    all*.exclude group: 'log4j', module: 'log4j'
    all*.exclude group: 'org.slf4j', module: 'slf4j-log4j12'
}

test {
    useJUnitPlatform()
}

// For details see https://github.com/radarsh/gradle-test-logger-plugin
testlogger {
    theme 'mocha'
    slowThreshold 5000
    showStandardStreams true
    showFullStackTraces false
    logLevel 'QUIET'
}


// declare the dependencies for your production and test code
dependencies {
    // --------------------------------------------------------------
    // Dependencies that should be part of the shadow jar, e.g.
    // connectors. These must be in the flinkShadowJar configuration!
    // --------------------------------------------------------------
    // Core
    implementation "org.apache.flink:flink-streaming-java:${flinkVersion}"
    implementation "org.apache.flink:flink-runtime-web:${flinkVersion}"

    // Connectors & Formats
    implementation "org.apache.flink:flink-connector-kafka:${flinkVersion}"

    // Logging
    implementation "org.apache.logging.log4j:log4j-api:${log4jVersion}"
    implementation "org.apache.logging.log4j:log4j-core:${log4jVersion}"
    implementation "org.apache.logging.log4j:log4j-slf4j-impl:${log4jVersion}"
    implementation "org.slf4j:slf4j-log4j12:${slf4jVersion}"

    flinkShadowJar "org.apache.avro:avro:${avroVersion}"
    flinkShadowJar "org.apache.flink:flink-avro:${flinkVersion}"
    implementation "org.apache.flink:flink-clients:${flinkVersion}"
    implementation "org.apache.flink:flink-java:${flinkVersion}"
    implementation "org.apache.flink:flink-s3-fs-presto:${flinkVersion}"
    flinkShadowJar "org.apache.flink:flink-avro-confluent-registry:${flinkVersion}"
    flinkShadowJar "io.confluent:kafka-schema-registry-client:${kafkaSchemaRegistryVersion}"
    flinkShadowJar "org.apache.flink:flink-metrics-influxdb:${flinkVersion}"
    flinkShadowJar "org.apache.flink:flink-metrics-core:${flinkVersion}"
    // Supplementary Libraries
    implementation "com.typesafe:config:${typesafeVersion}"
    // https://mvnrepository.com/artifact/org.influxdb/influxdb-java
    implementation 'org.influxdb:influxdb-java:2.23'

    // -----------------------------------------------------------------
    // Dependencies that should be part of the shadow jar, e.g connectors.
    // -----------------------------------------------------------------
    flinkShadowJar "org.apache.flink:flink-connector-kafka:${flinkVersion}"

    // Supplementary Libraries
    flinkShadowJar "com.typesafe:config:${typesafeVersion}"

    // -----------------------------------------------------------------
    // Add test dependencies here.
    // -----------------------------------------------------------------
    testRuntimeOnly "org.junit.jupiter:junit-jupiter-engine:${junitVersion}"
    testImplementation "org.junit.jupiter:junit-jupiter-api:${junitVersion}"
    testImplementation group: 'org.assertj', name:'assertj-core', version: "${assertjVersion}"

    testImplementation "org.apache.flink:flink-test-utils:${flinkVersion}"
    testImplementation "org.apache.flink:flink-runtime:${flinkVersion}:tests"
    testImplementation "org.apache.flink:flink-streaming-java:${flinkVersion}:tests"
}

// make compileOnly dependencies available for tests:
sourceSets {
    main.compileClasspath += configurations.flinkShadowJar
    main.runtimeClasspath += configurations.flinkShadowJar

    test.compileClasspath += configurations.flinkShadowJar
    test.runtimeClasspath += configurations.flinkShadowJar

    javadoc.classpath += configurations.flinkShadowJar
}

run.classpath = sourceSets.main.runtimeClasspath

jar {
    manifest {
        attributes 'Built-By': System.getProperty('user.name'),
                'Build-Jdk': System.getProperty('java.version')
    }
}

shadowJar {
    baseName 'flink-stream-job'
    zip64 true
    configurations = [project.configurations.flinkShadowJar]
}

spotless {
    java {
        target fileTree('.') {
            include '**/*.java'
            exclude '**/build/**', '**/build-*/**'
        }
        toggleOffOn()
        googleJavaFormat()
        removeUnusedImports()
        trimTrailingWhitespace()
        endWithNewline()
    }
}